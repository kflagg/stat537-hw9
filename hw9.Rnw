\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{float}
\usepackage{amsmath}

\usepackage{enumitem}
\setlist{parsep=5.5pt}

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Stat 537 Homework 9}
\chead{April 21, 2016}
\rhead{Andrea Mack and Kenny Flagg}
\setlength{\headheight}{18pt}
\setlength{\headsep}{2pt}

\title{Stat 537 Homework 9}
\author{Andrea Mack and Kenny Flagg}
\date{April 21, 2016}

<<setup, echo=FALSE, message=FALSE, cache=FALSE>>=
require(knitr)
opts_chunk$set(echo = FALSE, comment = NA, width = 80,
               fig.align = 'center', fig.width = 6, fig.height = 3,
               out.width = '6in', out.height = '3in', size = 'footnotesize',
               dev = 'pdf', dev.args = list(pointsize = 8))
knit_theme$set('print')

require(xtable)
require(psych)
require(lavaan)
require(polycor)
require(semPlot)
@

\begin{document}

\maketitle

{\it You can works in groups of up to 3, no restrictions on composition.}

{\it You can find the survey used to generate the "eat" labeled questions you will be working with here: \verb|https://psychology-tools.com/eat-26/|}

{\it The numbers on the ``eat'' questions are the same as in the online survey although the version you have used a 7-point Likert scale (with 7 a ) instead of the 6 point version on the website. bmi is a version of the body mass index, wsb is a score on western standards of beauty with (I assume) higher scores relating to higher self-perceived beauty of the subject, and anx is an anxiety score with (I assume) higher scores relating to higher anxiety.}

{\it Note that there are some missing values in the data set that were coded as -99. The following code will get you going on this but is not complete:}

<<cleanup, warning=FALSE, fig.height=6, out.height='6in', cache=TRUE, include = FALSE>>=
eatingatt_data <- read.csv('eatingattitudes.csv', na.strings = -99)

# Cleaning up the data set to allow focus on other aspects -- could retain nearly 60 partial observations
ead_c <- na.omit(eatingatt_data)
describe(ead_c)
@

\begin{enumerate}

\item %1
{\it First make a table of the questions being used here and rename each ``eat'' variable to make it more explicit about what the question was focused on.}

\begin{table}[h!]
\caption{Variable Names}
\centering
\begin{tabular}{l|l}
ow & I am terrified about being overweight.\\
avoid & I avoid eating when I am hungry.\\
guilt & I feel extremely guilty after eating.\\
occ & I am occupied with a desire to be thinner.\\
burn & I think about burning up calories when I exercise.\\
fat & I am preoccupied with the thought of having fat on my body.\\
empty & I like my stomach to be empty.\\
food & I find myself preoccupied with food.\\
control & I feel that food controls my life.\\
time & I give too much time and thought to food.\\
bmi & calculuated\\
wsb & western standards beauty score\\
anx & anxiety score\\
\end{tabular}
\end{table}

{\it Using your new names re-run the provided cor.plot code (you do not need to report the previous plot). I had some plot margins too large issues in compiling in markdown with this plot until I changed the figure size. You can always do it in outside of markdown and load the figure back into the final compile if these options don't work for you. Then:}

<<cor.plot, fig.height=6, out.height='6in'>>=
colnames(ead_c) <- c("id", "ow", "avoid", "guilt", "occ", "burn", "fat",
                     "empty", "food", "control", "time", "bmi", "wsb", "anx")
poly.cor <- mat.sort(cor(ead_c[,-c(1, 12:14)]))
cor.plot(mat.sort(cor(ead_c[,-c(1, 12:14)])))
@

\item %2
{\it Discuss the correlation matrix pattern.}

It appears being preoccupied with food has a strong positive correlation with feeling food controls a respondant's life, and both of these also have strong positive correlations with feeling a respondant gives too much time and thought to food.

Being preoccupied with having fat on the body was strongly positively associated with feeling guilty after eating, and both of these have strong positive associations with being preoccupied with a desire to be thinner.

All the variable have positive correlations.

\pagebreak
\item %3
{\it Use the help information to explain how mat.sort() sorted the correlation matrix.}

{\texttt mat.sort()} is defaulting to sorting the variables in descending order based on loading from an exploratory factor analysis on the correlation matrix between the variables. This sorts the manifest variables by the amount of variation in common with the first latent factor, in decreasing order.

\item %4
{\it The previous result was using Pearson correlation. Identify a more appropriate correlation measure for these data (report it). Then estimate the correlation matrix using functions from the polycor package (not psych) and compare the correlations to those produced by Pearson correlation here, comparing the estimates and remaking the correlation matrix plot.}

These variables are all ordered categorical (Likert-scale) variables, so it would be more appropriate to use polychoric correlation.

<<het.plot, warning=FALSE, fig.height=6, out.height='6in', cache=TRUE>>=
# Rename eat variables and then proceed with the following...
edo <- apply(ead_c[,-c(1, 12:14)], 2, ordered)
het <- hetcor(edo)
cor.plot(mat.sort(het$correlations))
@

<<compare.cors, fig.height=4.5, out.height='4.5in', fig.width=4.5, out.width='4.5in', cache=TRUE, dependson='het.plot'>>=
plot(jitter(het$correlations)~jitter(cor(ead_c[,-c(1, 12:14)])),
     main = 'Comparison of Correlations',
     xlab = 'Pearson Correlation', ylab = 'Polychoric Correlation',
     col = rgb(0, 0, 0, 0.25), pch = 19)
abline(0, 1, lty = 2)
@

For weakly correlated variables (with correlations under 0.4), the Pearson and polychoric correlations are very similar. For moderately and strongly associated variable (correlations above 0.4), the polychoric correltions are slightly larger.

\item %5
{\it Using your better named variables and your ``better'' correlation matrix, fit a CFA that puts eat21, eat3, and eat18 together on one latent trait and the other eat variables on the other. To make sure it is using your correlation matrix, use sample.cov and sample.nobs and do not provide the data set to the cfa function from lavaan. Report the summary output from the model with the latent trait variances fixed at one.}

<<cfa, cache=TRUE, dependson='het.plot'>>=
# eat21 is time, eat3 is food, eat18 is control
cfa.model1 <- '
  PreoccupiedWithFood =~ food + control + time
  Other =~ ow + avoid + guilt + occ + burn + fat + empty
'
het.cfa <- cfa(model = cfa.model1, sample.cov = as.matrix(het), sample.nobs = nrow(edo), std.lv = TRUE)
summary(het.cfa, fit.measures = TRUE)
@

\item %6
{\it Make a path diagram of the resulting model.}
<<paths, cache=TRUE, dependson='cfa'>>=
par(mar = c(0, 0, 0, 0))
semPaths(het.cfa, "par", edge.label.cex = 1.5, sizeMan = 10, sizeLat = 12)
@

\item %7
{\it Discuss the quality of the fit of the model using (a) the goodness of fit test and (b) one of the other measures of quality of fit. Make sure to fully report the numerical results as well as discussing what this tells you about the model.}

\begin{enumerate}

\item %a
With a \(\chi^2_{34}\) test statistic of 114.706 and \(\text{p-value}<0.001\), there is strong evidence that a more complex model is needed to accurately reconstruct the sample correlation matrix.

How could we assess kurtosis? Lots of kurtosis-> this is a bad measure.

\item %b
The root mean square error of approximation is estimated to be 0.099. This exceeds the rule-of-thumb threshold of 0.05, suggesting that there is room for improvement in the model fit. {\it I actually have a note saying the RMSEA is not the root mean square index.}

\end{enumerate}

\item %8
{\it Discuss all the loadings -- are there any that potentially could be dropped?}

All the loadings have associated pvalues of less than 0.001, indicating strong evidence they are not zero. None could potentially be dropped. (EH 211)

\item %9
{\it Report and discuss the disattenuated correlation of the latent traits. Does this make sense in this application?}

The correlation between the true preoccupied with food variable and the true other variable is 0.65. It makes sense that the true preoccupied latent trait would be moderately positively correlated with the other latent trait because the variables that loaded on the other latent trait were {\texttt ow, avd, glt, occ, brn, fat}, and {\texttt emp}. These manifest variables also desribe traits of people that may be overly conscious of their weight.

\item %10
{\it Add the other three variables to your correlation matrix using appropriate correlation measures. Note the types of correlations you are using (you can discuss this generally). Also update your correlation matrix plot using this matrix.}

<<mixedcor, cache = TRUE>>=
ead_c1 <- ead_c[,-1]
ead_c1$ow <- ordered(ead_c$ow)
ead_c1$avoid <- ordered(ead_c$avoid)
ead_c1$guilt <- ordered(ead_c$guilt)
ead_c1$occ <- ordered(ead_c$occ)
ead_c1$burn <- ordered(ead_c$burn)
ead_c1$fat <- ordered(ead_c$fat)
ead_c1$empty <- ordered(ead_c$empty)
ead_c1$food <- ordered(ead_c$food)
ead_c1$control <- ordered(ead_c$control)
ead_c1$time <- ordered(ead_c$time)
ead_c1$wsb <- ordered(ead_c$wsb)
ead_c1$anx <- ordered(ead_c$anx)


het1 <- hetcor(ead_c1, use = "pairwise")
het1
cor.plot(mat.sort(het1))
@

We used the {\texttt hetcor} function from the {\texttt polycor} package to re-calculate the correlation matrix with all 14 variables. The function used polychoric correlations for all pairs of variables except variables paired with {\texttt bmi}, in which polyserial correlation was used.

<<compare>>=
subset.rho <- mix.cor$rho[-c(11:14),-c(11:14)]
poly.cor - subset.rho



@

Not sure what's wrong.

\item %11
{\it Fit an SEM that retains the same latent variable construction as in the CFA but that also uses bmi, anx, and wsb as exogenous variables that explain both of the latent traits. Fit the model and report the summary. Also make a path diagram.}

\item %12
{\it Report the evidence and discuss the interpretation of the two tests for the paths that relate bmi to each of the latent traits.}

\item %13
{\it Generally explain what this model is exploring.}

\end{enumerate}

\pagebreak
\section*{R Code Appendix}

\subsection*{Problem 1}

<<cleanup, echo=TRUE, eval=FALSE>>=
@
<<cor.plot, echo=TRUE, eval=FALSE>>=
@

\subsection*{Problem 4}

<<hetplot, echo=TRUE, eval=FALSE>>=
@
<<compare.cors, echo=TRUE, eval=FALSE>>=
@

\subsection*{Problem 5}

<<cfa, echo=TRUE, eval=FALSE>>=
@

\subsection*{Problem 6}

\subsection*{Problem 7}

\subsection*{Problem 8}

\subsection*{Problem 9}

\subsection*{Problem 10}

\subsection*{Problem 11}

\subsection*{Problem 12}

\subsection*{Problem 13}

\end{document}
